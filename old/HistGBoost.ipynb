{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28cc66f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of cpu kernels\n",
    "import os\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ceb62fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "data = pd.read_csv(\"data.csv\", delimiter=\";\")\n",
    "X = data.drop(\"Target\", axis=1)\n",
    "y = data[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2d1318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering function\n",
    "def engineer_features(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Academic performance features\n",
    "    X['academic_progress_rate'] = (\n",
    "        X['Curricular units 1st sem (approved)'] + \n",
    "        X['Curricular units 2nd sem (approved)']\n",
    "    ) / (\n",
    "        X['Curricular units 1st sem (enrolled)'] + \n",
    "        X['Curricular units 2nd sem (enrolled)'] + 1e-6\n",
    "    )\n",
    "    \n",
    "    X['overall_grade_avg'] = (\n",
    "        X['Curricular units 1st sem (grade)'] + \n",
    "        X['Curricular units 2nd sem (grade)']\n",
    "    ) / 2\n",
    "    \n",
    "    X['failure_rate'] = (\n",
    "        (X['Curricular units 1st sem (enrolled)'] - \n",
    "         X['Curricular units 1st sem (approved)']) / \n",
    "        (X['Curricular units 1st sem (enrolled)'] + 1e-6)\n",
    "    )\n",
    "    \n",
    "    # Financial/demographic features\n",
    "    X['financial_risk'] = (X['Tuition fees up to date'] == 0) & (X['Scholarship holder'] == 0)\n",
    "    X['age_course_interaction'] = X['Age at enrollment'] * X['Course']\n",
    "    X['parent_education_max'] = X[[\"Mother's qualification\", \"Father's qualification\"]].max(axis=1)\n",
    "    \n",
    "    # Time-based features\n",
    "    X['grade_consistency'] = abs(\n",
    "        X['Curricular units 1st sem (grade)'] - \n",
    "        X['Curricular units 2nd sem (grade)']\n",
    "    )\n",
    "    \n",
    "    X['early_warning'] = (\n",
    "        X['Curricular units 1st sem (approved)'] / \n",
    "        (X['Curricular units 1st sem (enrolled)'] + 1e-6)\n",
    "    ) < 0.5\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0131a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "X_engineered = engineer_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f534f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "one_hot_columns = [\n",
    "    \"Marital status\",\n",
    "    \"Application mode\",\n",
    "    \"Course\",\n",
    "    \"Previous qualification (grade)\",\n",
    "    \"Nacionality\",\n",
    "    \"Mother's qualification\",\n",
    "    \"Father's qualification\",\n",
    "    \"Mother's occupation\",\n",
    "    \"Father's occupation\",\n",
    "]\n",
    "for col in one_hot_columns:\n",
    "    data[col].convert_dtypes(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be505811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_engineered, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59563eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#from imblearn.pipeline import Pipeline\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Select the k best features based on ANOVA F-value\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=10)\n",
    "# Pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "#        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"feature_selection\", feature_selector),\n",
    "        (\"classifier\", HistGradientBoostingClassifier(\n",
    "            early_stopping=True,  # Enable validation-based stopping\n",
    "            scoring='f1_macro',   # Align with CV metric\n",
    "            validation_fraction=0.1,\n",
    "            n_iter_no_change=10,  # Stop if no improvement in 10 iterations\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced\",\n",
    "            categorical_features=\"from_dtype\"\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5769291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, loguniform, randint\n",
    "# Parameter distribution Randomized search\n",
    "param_dist = {\n",
    "    \"feature_selection__k\": [5, 10, 15, 20],\n",
    "    \n",
    "    \"classifier__learning_rate\": loguniform(0.01, 0.2),\n",
    "    \"classifier__max_iter\": randint(200, 800),\n",
    "    \"classifier__max_leaf_nodes\": randint(15, 128),\n",
    "    \"classifier__max_depth\": [None, 5, 10, 20],\n",
    "    \"classifier__min_samples_leaf\": randint(10, 50),\n",
    "    \"classifier__l2_regularization\": loguniform(1e-3, 1),\n",
    "    \"classifier__max_bins\": [128, 255],\n",
    "    \"classifier__max_features\": uniform(0.6, 0.4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8353097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      " Best parameters found: {'classifier__l2_regularization': np.float64(0.016267099368894124), 'classifier__learning_rate': np.float64(0.13702370114575005), 'classifier__max_bins': 128, 'classifier__max_depth': 5, 'classifier__max_features': np.float64(0.771564497559442), 'classifier__max_iter': 284, 'classifier__max_leaf_nodes': 62, 'classifier__min_samples_leaf': 42, 'feature_selection__k': 20}\n",
      "\n",
      " Best score found: 0.707919499135836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Construct randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "print(f\"\\n Best parameters found: {best_params}\")\n",
    "print(f\"\\n Best score found: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef04f19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[207  66  31]\n",
      " [ 20  98  40]\n",
      " [ 12  74 337]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5b2ecb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.87      0.68      0.76       304\n",
      "    Enrolled       0.41      0.62      0.49       158\n",
      "    Graduate       0.83      0.80      0.81       423\n",
      "\n",
      "    accuracy                           0.73       885\n",
      "   macro avg       0.70      0.70      0.69       885\n",
      "weighted avg       0.77      0.73      0.74       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d6c51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
